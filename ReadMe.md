### LLM 동작 원리  
  
1. 질문 이해  
토큰 단위로 문장을 쪼갠 후, 각 토큰을 '의미지도' 위의 고유한 좌표(숫자)로 변환. 이를 통해 단어의 의미와 관계를 이해  
  
3. 문맥 파악  
'어텐션'을 통해 문장 전체를 보고 단어 간의 관계를 파악  
  
5. 한 단어씩 답변 생성  
이해한 맥락을 바탕으로, 다음에 올 가장 확률 높은 단어 한 단어씩 예측해 문장 완성.

### LLM 상용과 무료  
  
|구분 | Open LLM(무료/ 오픈소스) | 상용 LLM (유료/ 폐쇄형) | 
|------|---|------|
|대표 모델|LLaMA 2/3 (Meta), Mistral, Falcon, BLOOM, Gemma, DeepSeek, Qwen 등|GPT-4 (OpenAI), Claude (Anthropic), Gemini (Google), Grok (xAI), HyperCLOVA X (Naver) 등|
|개발 주체|연구기관, 빅테크, 오픈 커뮤니티(Meta, HuggingFace 등)|대형 기업 (OpenAI, Google, Anthropic, Microsoft, Naver 등)| 
|공개 여부|모델 가중치, 아키텍처 대부분 공개| 모델 내부 구조/가중치 비공개|
|비용|무료 사용 가능 (연구, 개인/기업 자유롭게 활용)|API 사용 시 과금 (토큰 단위 요금)|
|성능 수준|GPT-3.5 ~ GPT-4에 근접,빠르게 발전 중|현재 최고 성능 (복잡한 추론, 멀티모달 지원 등)|
|확장성/자유도| 파인튜닝, 로컬 실행, 커스터마이징 자유로움 | API 중심, 커스터마이징 제한적|
|하드웨어 요구사항|대형 모델은 GPU 다수 필요, 소형 모델은 PC에서도 실행 가능 |클라우드 제공 (사용자 하드웨어 불필요)|
|한국어 지원|일부 모델은 제한적 (영어/중국어 최적화가 많음), 한국어 튜닝 필요|GPT-4, Gemini → 한국어지원 우수 /HyperCLOVA X → 한국어 특화|
|활용 분야|연구, 실험, 교육, 기업 내 폐쇄망 서비스|상용 서비스, 대규모 제품 적용, 최고 성능 필요한 분야|
|장점|무료, 투명성, 연구와 학습에 적합, 로컬에서 데이터 보안 보장|최고 성능, 안정성, 유지보수/업데이트 제공, 다양한 언어와 기능 지원|  
|단점 | 성능 격차(아직 GPT-4보다 낮음), 실행에 고성능자원 필요|비용 발생, 모델 내부 불투명, 특정 기업 의존|  
  
### LLM 성능 평가(Benchmark)   
대표적 예시: GPQA 질문(기본 질문 데이터셋)을 통해 정확도를 보고 성능 평가 가능   
1. 왜 벤치마크가 필요한가?    
LLM(대규모 언어 모델)은 매우 복잡한 블랙박스처럼 보입니다. (수십억~수천억 개의 파라미터, 방대한 데이터)    
모델이 실제로 얼마나 잘 이해하고, 추론하고, 대답하는지를 객관적으로 알기 어렵습니다.   
그래서 벤치마크(benchmark) 라는 표준 시험지가 필요합니다.    
- 모델을 동일한 조건에서 시험 봐서 성능 비교  
   
2. 벤치마크가 평가하는 것   
언어 이해: 문장 의미 파악, 독해 능력 (GLUE, SuperGLUE)   
지식/상식: 일반 지식 문제 풀이 (MMLU, TriviaQA)   
수학/논리 추론: 계산, 논리 퍼즐 (GSM8K, MathQA)   
코딩 능력: 코드 작성/디버깅 (HumanEval, MBPP)   
멀티모달: 이미지+텍스트 이해 (MMBench 등)  
즉, 벤치마크는 모델의 "과목별 성적표" 역할을 함.  
  
3. 왜 연구자와 개발자에게 중요한가?  
공정한 비교: GPT, Claude, LLaMA 같은 모델을 같은 시험지로 비교해야 성능 차이를 명확히 알 수 있음.    
연구 발전: 새로운 모델이 나왔을 때 “이전 모델보다 얼마나 나아졌는가?”를 증명하는 근거 제공.  
실제 적용성 판단: 예를 들어, 코딩 보조에 쓸 모델을 찾는다면 HumanEval 점수를 보고 선택 의학 분야라면 MedMCQA 같은 전문 벤치마크 점수 참고  
약점 발견: 어떤 모델이 언어 이해는 뛰어나지만 수학은 약한지 파악 가능 → 개선 방향 설정   

| 평가 항목 | 설명 | 측정 방법 |
|------|---|------|
|응답 속도(Latency) | 질의에 대한 평균 시간(ms) |API|
|처리량(Thoughput)| 초당 처리 가능한 토큰 |------|
|정확성 (Accuracy)| 정답률, 평가 데이터셋에서의 정밀도|BLEU, ROUGE, GPT-4 평가 결과 비교 |
|일관성(Consistency)| 동일한 입력에 대해 결과가 얼마나 일관적인지 |다회 테스트 결과 비교 |
|메모리 사용량 (Memory Usage)|모델이 실행되는 동안 차지하는 RAM 및 VRAM| 시스템 모니터링 (온프레미스인 경우)|
|스케일링 가능성| 부하가 증가할 때 성능이 어떻게 변화하는지 |동시 요청 증가 테스트|
| 다국어 지원 | 다국어(한국어) 지원 여부|다국어 응답 결과 테스트, 가이드 참조|  
  
4. TPS(Tokens per Second)    
모델이 초당 생성하거나 처리할 수 있는 토큰 수.   
언어 모델(LLM)이나 API가 얼마나 빠르게 텍스트를 처리할 수 있는지를 측정하는 성능 지표입니다.   
  
       총 처리된 토큰 수  
TPS = ________________
        걸린 시간(초)  












