LLM 동작 원리  
  
1. 질문 이해  
토큰 단위로 문장을 쪼갠 후, 각 토큰을 '의미지도' 위의 고유한 좌표(숫자)로 변환. 이를 통해 단어의 의미와 관계를 이해  
  
3. 문맥 파악  
'어텐션'을 통해 문장 전체를 보고 단어 간의 관계를 파악  
  
5. 한 단어씩 답변 생성  
이해한 맥락을 바탕으로, 다음에 올 가장 확률 높은 단어 한 단어씩 예측해 문장 완성.

LLM 상용과 무료  
  
|구분 | Open LLM(무료/ 오픈소스) | 상용 LLM (유료/ 폐쇄형) | 
|------|---|------|
|대표 모델|LLaMA 2/3 (Meta), Mistral, Falcon, BLOOM, Gemma, DeepSeek, Qwen 등|GPT-4 (OpenAI), Claude (Anthropic), Gemini (Google), Grok (xAI), HyperCLOVA X (Naver) 등|
|개발 주체|연구기관, 빅테크, 오픈 커뮤니티(Meta, HuggingFace 등)|대형 기업 (OpenAI, Google, Anthropic, Microsoft, Naver 등)| 
|공개 여부|모델 가중치, 아키텍처 대부분 공개| 모델 내부 구조/가중치 비공개|
|비용|무료 사용 가능 (연구, 개인/기업 자유롭게 활용)|API 사용 시 과금 (토큰 단위 요금)|
|성능 수준|GPT-3.5 ~ GPT-4에 근접,빠르게 발전 중|현재 최고 성능 (복잡한 추론, 멀티모달 지원 등)|
|확장성/자유도| 파인튜닝, 로컬 실행, 커스터마이징 자유로움 | API 중심, 커스터마이징 제한적|
|하드웨어 요구사항|대형 모델은 GPU 다수 필요, 소형 모델은 PC에서도 실행 가능 |클라우드 제공 (사용자 하드웨어 불필요)|
|한국어 지원|일부 모델은 제한적 (영어/중국어 최적화가 많음), 한국어 튜닝 필요|GPT-4, Gemini → 한국어지원 우수 /HyperCLOVA X → 한국어 특화|
|활용 분야|연구, 실험, 교육, 기업 내 폐쇄망 서비스|상용 서비스, 대규모 제품 적용, 최고 성능 필요한 분야|
|장점|무료, 투명성, 연구와 학습에 적합, 로컬에서 데이터 보안 보장|최고 성능, 안정성, 유지보수/업데이트 제공, 다양
한 언어와 기능 지원|
|단점 | 성능 격차(아직 GPT-4보다 낮음), 실행에 고성능자원 필요|비용 발생, 모델 내부 불투명, 특정 기업 의존|
  
GPQA 질문(기본 질문 데이터셋)을 통해 정확도를 보고 성능 평가 가능  
